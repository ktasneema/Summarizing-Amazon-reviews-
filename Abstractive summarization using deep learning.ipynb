{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFuL-RBgXqgU"
   },
   "source": [
    "### Text Summarization using deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we will build an abstractive based text summarizer using deep learning from the scratch in python using keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5dSoP8lGMZi"
   },
   "source": [
    "Customer reviews can often be long and descriptive. Analyzing these reviews manually, as you can imagine, is really time-consuming. This is where the brilliance of Natural Language Processing can be applied to generate a summary for long reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Attention Layer\n",
    "Keras does not officially support attention layer. So, we can either implement our own attention layer or use a third-party implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fi64aA0FFxcS"
   },
   "outputs": [],
   "source": [
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUValOzcHtEK"
   },
   "source": [
    "#Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "_Jpu8qLEFxcY",
    "outputId": "95968e01-faac-4911-c802-9c008a4e62cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVakjZ3oICgx"
   },
   "source": [
    "#Read the dataset\n",
    "\n",
    "This dataset consists of reviews of fine foods from Amazon. The data spans a period of more than 10 years, including all ~500,000 reviews up to October 2012. These reviews include product and user information, ratings, plain text review, and summary. It also includes reviews from all other Amazon categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnK5o4Z1Fxcj"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGNQKvCaISIn"
   },
   "source": [
    "### Drop Duplicates and NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cjul88oOFxcr"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qi0xD6BkIWAm"
   },
   "source": [
    "###  Dataset details\n",
    "\n",
    "Let us look at datatypes and shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__fy-JxTFxc9",
    "outputId": "d42c6e36-bbc8-43c2-de0e-d3effe3e8c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19308 entries, 0 to 19978\n",
      "Data columns (total 10 columns):\n",
      "Id                        19308 non-null int64\n",
      "ProductId                 19308 non-null object\n",
      "UserId                    19308 non-null object\n",
      "ProfileName               19308 non-null object\n",
      "HelpfulnessNumerator      19308 non-null int64\n",
      "HelpfulnessDenominator    19308 non-null int64\n",
      "Score                     19308 non-null int64\n",
      "Time                      19308 non-null int64\n",
      "Summary                   19308 non-null object\n",
      "Text                      19308 non-null object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0xLYACiFxdJ"
   },
   "source": [
    "#Preprocessing\n",
    "\n",
    "Performing basic preprocessing steps is very important before we get to the model building part. Using messy and uncleaned text data is a potentially disastrous move. So in this step, we will drop all the unwanted symbols, characters, etc. from the text that do not affect the objective of our problem.\n",
    "we are using contraction_mapping as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s6IY-x2FxdL"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JFRXFHmI7Mj"
   },
   "source": [
    "We will perform the below preprocessing tasks for our data:\n",
    "\n",
    "1.Convert everything to lowercase\n",
    "\n",
    "2.Remove HTML tags\n",
    "\n",
    "3.Contraction mapping\n",
    "\n",
    "4.Remove (‘s)\n",
    "\n",
    "5.Remove any text inside the parenthesis ( )\n",
    "\n",
    "6.Eliminate punctuations and special characters\n",
    "\n",
    "7.Remove stopwords\n",
    "\n",
    "8.Remove short words\n",
    "\n",
    "Let’s define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZr-u3OEFxdT"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2QAeCHWFxdY"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snRZY8wjLao2"
   },
   "source": [
    "Let us look at the first five preprocessed reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCAIkhWbFxdh",
    "outputId": "c2da1a36-4488-4e32-ef9e-fcfe496e374d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsRXocxoFxd-"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZeD0gs6Lnb-"
   },
   "source": [
    "Let us look at the first 10 preprocessed summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQJdZcAzFxee",
    "outputId": "a1fbe683-c03f-4afb-addf-e075021c121b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1zLpnqsFxey"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KT_D2cLiLy77"
   },
   "source": [
    "### Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYK390unFxfA"
   },
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdF76AHHFxgw",
    "outputId": "e3bbe165-4235-482f-bfd4-36a3f1d95290"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwdSGIhGMEbz"
   },
   "source": [
    "Fix the maximum length of the summary to 8 since that seems to be the majority summary length.\n",
    "proportion of the length of summaries below 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JRjwdIOFxg3",
    "outputId": "f968be82-c539-471d-ce23-16f18b059ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9430245217481467\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYB4Ga9KMjEu"
   },
   "source": [
    "We observe that 94% of the summaries have length below 8. So, we can fix maximum length of summary to 8.\n",
    "\n",
    "Let us fix the maximum length of review to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKD5VOWqFxhC"
   },
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6d48E-8M4VO"
   },
   "source": [
    "Let us select the reviews and summaries whose length falls below or equal to **max_text_len** and **max_summary_len**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yY0tEJP0FxhI"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tR1uh8xSNUma"
   },
   "source": [
    "Remember to add the **START** and **END** special tokens at the beginning and end of the summary. Here, I have chosen **sostok** and **eostok** as START and END tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwLUH78CFxhg"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RakakKHcFxhl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vq1mqyOHOtIl"
   },
   "source": [
    "#Preparing the Tokenizer\n",
    "\n",
    "A tokenizer builds the vocabulary and converts a word sequence to an integer sequence. Go ahead and build tokenizers for text and summary:\n",
    "\n",
    "#Text Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRHTgX6hFxhq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzvLwYL_PDcx"
   },
   "source": [
    "\n",
    "\n",
    "Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8KronV2Fxhx",
    "outputId": "d2eb2f27-fbbc-4e61-9556-3c3ff5e4327b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 66.89049586776859\n",
      "Total Coverage of rare words: 6.417143627086275\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "So-J-5kzQIeO"
   },
   "source": [
    "**Remember**:\n",
    "\n",
    "\n",
    "* **tot_cnt** gives the size of vocabulary (which means every unique words in the text)\n",
    " \n",
    "*   **cnt** gives me the no. of rare words whose count falls below threshold\n",
    "\n",
    "*  **tot_cnt - cnt** gives me the top most common words \n",
    "\n",
    "Let us define the tokenizer with top most common words for reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2giEsF3Fxh3"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCbGMsm4FxiA",
    "outputId": "2d9165f0-e542-4114-91f3-e070d483fce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3847"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQfKP3sqRxi9"
   },
   "source": [
    "#Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRHqyBkBFxiJ"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KInA6O6ZSkJz"
   },
   "source": [
    "#Rarewords and its Coverage\n",
    "\n",
    "Let us look at the proportion rare words and its total coverage in the entire summary\n",
    "\n",
    "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzE5OiRLFxiM",
    "outputId": "7f7a4f89-b088-4847-8172-09e5a2383d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 82.33944954128441\n",
      "Total Coverage of rare words: 10.91750944315828\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PBhzKuRSw_9"
   },
   "source": [
    "Let us define the tokenizer with top most common words for summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fswLvIgFxiR"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqwDUT5oTFmn"
   },
   "source": [
    "Let us check whether word count of start token is equal to length of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR8IX9FRFxiY",
    "outputId": "b116cdbd-42c4-4ede-9f6d-46284115393e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9470, 9470)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVFhFVguTTtw"
   },
   "source": [
    "Here, I am deleting the rows that contain only **START** and **END** tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ-vW82sFxih"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx5NISuMFxik"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOtlDcthFxip"
   },
   "source": [
    "###  Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXef38nBFxir",
    "outputId": "7ae99521-46f8-4c6f-9cba-4979deffeee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      384700      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    69400       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer [(None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 694)    417094      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,456,294\n",
      "Trainable params: 3,456,294\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lwfi1Fm8Fxiz"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-A3J92MUljB"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mw6CVECaUq5b"
   },
   "source": [
    "We’ll train the model on a batch size of 128 and validate it on the holdout set (which is 10% of our dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETnPzA4OFxi3",
    "outputId": "477e374f-7cf2-4d60-f86e-2c49c9cebedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8956 samples, validate on 999 samples\n",
      "Epoch 1/50\n",
      "8956/8956 [==============================] - 390s 44ms/sample - loss: 2.8316 - val_loss: 2.4218\n",
      "Epoch 2/50\n",
      "8956/8956 [==============================] - 306s 34ms/sample - loss: 2.3531 - val_loss: 2.3101\n",
      "Epoch 3/50\n",
      "8956/8956 [==============================] - 307s 34ms/sample - loss: 2.2671 - val_loss: 2.2680\n",
      "Epoch 4/50\n",
      "8956/8956 [==============================] - 310s 35ms/sample - loss: 2.2165 - val_loss: 2.2353\n",
      "Epoch 5/50\n",
      "8956/8956 [==============================] - 320s 36ms/sample - loss: 2.1685 - val_loss: 2.2020\n",
      "Epoch 6/50\n",
      "8956/8956 [==============================] - 302s 34ms/sample - loss: 2.1230 - val_loss: 2.1723\n",
      "Epoch 7/50\n",
      "8956/8956 [==============================] - 297s 33ms/sample - loss: 2.0776 - val_loss: 2.1442\n",
      "Epoch 8/50\n",
      "8956/8956 [==============================] - 290s 32ms/sample - loss: 2.0269 - val_loss: 2.1048\n",
      "Epoch 9/50\n",
      "8956/8956 [==============================] - 293s 33ms/sample - loss: 1.9769 - val_loss: 2.0725\n",
      "Epoch 10/50\n",
      "8956/8956 [==============================] - 331s 37ms/sample - loss: 1.9282 - val_loss: 2.0467\n",
      "Epoch 11/50\n",
      "8956/8956 [==============================] - 331s 37ms/sample - loss: 1.8864 - val_loss: 2.0268\n",
      "Epoch 12/50\n",
      "8956/8956 [==============================] - 302s 34ms/sample - loss: 1.8482 - val_loss: 2.0149\n",
      "Epoch 13/50\n",
      "8956/8956 [==============================] - 305s 34ms/sample - loss: 1.8105 - val_loss: 2.0002\n",
      "Epoch 14/50\n",
      "8956/8956 [==============================] - 306s 34ms/sample - loss: 1.7766 - val_loss: 1.9931\n",
      "Epoch 15/50\n",
      "8956/8956 [==============================] - 311s 35ms/sample - loss: 1.7456 - val_loss: 1.9886\n",
      "Epoch 16/50\n",
      "8956/8956 [==============================] - 307s 34ms/sample - loss: 1.7158 - val_loss: 1.9843\n",
      "Epoch 17/50\n",
      "8956/8956 [==============================] - 318s 36ms/sample - loss: 1.6859 - val_loss: 1.9746\n",
      "Epoch 18/50\n",
      "8956/8956 [==============================] - 343s 38ms/sample - loss: 1.6588 - val_loss: 1.9816\n",
      "Epoch 19/50\n",
      "8956/8956 [==============================] - 303s 34ms/sample - loss: 1.6320 - val_loss: 1.9819\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ezKYOp2UxG5"
   },
   "source": [
    "#Understanding the Diagnostic plot\n",
    "\n",
    "Now, we will plot a few diagnostic plots to understand the behavior of the model over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDTNLAURFxjE",
    "outputId": "e2ea6e44-3931-4014-97a1-03fa2a441228"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBX0zZnOFxjW"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eM_nU_VvFxjq"
   },
   "source": [
    "# Inference\n",
    "\n",
    "Set up the inference for the encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QkrNV-4Fxjt"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f6TTFnBFxj6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GuDf4TPWt6_"
   },
   "source": [
    "Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAUntznIFxj9"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gM4ALyfWwA9"
   },
   "source": [
    "Here are a few summaries generated by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUtQmQTmFxkI",
    "outputId": "f407d9fc-e0cd-4082-98f5-bd1f562dc26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: loved packs flavors except chocolate covered melted one great big everyday summer cannot blame anyone \n",
      "Original summary: nuts great chocolate melted \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: like darker roast guess ok would buy brew middle selection keurig full cup \n",
      "Original summary: too mild \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: fill cups great use custom coffee come cup variety disposable fill several ready also drink herbal tea buy bulk make kuerig would definitely buy hand \n",
      "Original summary: great to have on \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: tablets really fun try parents friends loved well worked drink store bought orange juice though sickly sweet sugar added acid favorite fresh pineapple sucking limes \n",
      "Original summary: flavor \n",
      "Predicted summary:  good but not good\n",
      "\n",
      "\n",
      "Review: soup sweet left salt full sugar grams sugar per serving two servings sweet also dairy butter vegan someone dairy allergies \n",
      "Original summary: not soup \n",
      "Predicted summary:  not like the money\n",
      "\n",
      "\n",
      "Review: seriously food purchased baby ever eaten everything given poor thing gagged gagged every spoon tried \n",
      "Original summary: had to out \n",
      "Predicted summary:  not\n",
      "\n",
      "\n",
      "Review: definitely best tasting sure milk pods causing aftertaste tried coffee straight milk creamer tasted better \n",
      "Original summary: my favorite of the \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: love chip started dieting satisfy every bit salty cravings perfect taste amazing get bad reviews love \n",
      "Original summary: bad these are amazing \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good tasted like oatmeal cookies coconut rather small price might fly people pay healthy days \n",
      "Original summary: nom nom nom excellent \n",
      "Predicted summary:  yummy\n",
      "\n",
      "\n",
      "Review: wanted lite seeing product looked forward great bacon taste house taste greasy taste also buy product \n",
      "Original summary: ok \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: never bonsai go purchased japanese kit arrived thrilled everything needed instructions clear tree healthy never showed thank eve garden \n",
      "Original summary: perfect little \n",
      "Predicted summary:  cat food\n",
      "\n",
      "\n",
      "Review: good product price amazon excellent really like coming door subscribe save excellent way shop \n",
      "Original summary: cat food \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: expected great taste healthy good shipment packing great fair value order thank \n",
      "Original summary: great taste \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: hot full great jerky sauces love \n",
      "Original summary: full of flavor \n",
      "Predicted summary:  great hot chocolate\n",
      "\n",
      "\n",
      "Review: opening numerous bags found none chips flavoring completely plain gross even happen \n",
      "Original summary: off \n",
      "Predicted summary:  these are great\n",
      "\n",
      "\n",
      "Review: stuff really works makes lemons taste sweet gave friend loved ordered give friends great party idea try sorts foods change flavor fun experiment \n",
      "Original summary: really works \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: great assortment price give stars peppermint weak peppermint add extract nice cocoa flavor tho reminds homemade \n",
      "Original summary: very pleased \n",
      "Predicted summary:  not good\n",
      "\n",
      "\n",
      "Review: chili filling mildly spicy cooks well however makes microwave \n",
      "Original summary: good chili \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: ounces tad expensive would say drink grams sugar also negative sugar lover big enough quench thirst delicious enough find coming back natural citrus \n",
      "Original summary: small size and mediocre taste \n",
      "Predicted summary:  not as good as\n",
      "\n",
      "\n",
      "Review: excellent coffee flavor robust without bitter would give five star rating amount grounds produced drink last cup \n",
      "Original summary: you will need \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: truly best tried tried many like strong coffee turned bitter aftertaste try coffee strong flavorful smooth practically perfect love smell brews \n",
      "Original summary: bold yet smooth \n",
      "Predicted summary:  best coffee\n",
      "\n",
      "\n",
      "Review: made mistake thinking product simply brown sugar flavored splenda read product details stating actually brown sugar mistake \n",
      "Original summary: this product has sugar in it \n",
      "Predicted summary:  not\n",
      "\n",
      "\n",
      "Review: hot sauce good shipping fine would reccomend product people much else say hot sauce \n",
      "Original summary: good hot sauce \n",
      "Predicted summary:  great hot chocolate\n",
      "\n",
      "\n",
      "Review: ordered finding good cook olive oil first time trying ghee really like ran bought another brand ghee story definitely like one better wish bigger size \n",
      "Original summary: love it \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: able find base three dollars cents much cheaper amazon asking love natural roasted peanut taste kids love mixing \n",
      "Original summary: great product but buying it \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: really like light airy almost like chips instead cookies flavor yummy oreo chocolate know love \n",
      "Original summary: very good snack \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: even receive correct product received raw peanuts option return amazon allow contact got reply buy \n",
      "Original summary: terrible \n",
      "Predicted summary:  not\n",
      "\n",
      "\n",
      "Review: chips really good fun getting variety pack good regular chips probably also nearly fattening bad regular chips given healthier version want chips would highly recommend \n",
      "Original summary: delicious and healthy chips \n",
      "Predicted summary:  these are great\n",
      "\n",
      "\n",
      "Review: coffee great great bag said sure seller got bag sealed never opened \n",
      "Original summary: coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: found rice years ago went back regular rice since flavor second none might little expensive regular rice worth dissapointed \n",
      "Original summary: eating it for \n",
      "Predicted summary:  not good\n",
      "\n",
      "\n",
      "Review: product good tried house enjoyed however case ordered contained cups worth hassle sending back however would hesitate order item amazon \n",
      "Original summary: product good cups \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: plant arrived packaged healthy came good instructions growing enjoy raising \n",
      "Original summary: healthy interesting plant \n",
      "Predicted summary:  cat food\n",
      "\n",
      "\n",
      "Review: really good hard chew like beef nuggets dry much downside bag stays moist inside little messy try eat bag drive home grease \n",
      "Original summary: much better than beef \n",
      "Predicted summary:  not as good as\n",
      "\n",
      "\n",
      "Review: much better protein products even taste great fill like shakes work quickly relatively cheap good things get \n",
      "Original summary: great ingredients and quality product \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: like one add collection works fits nicely counter top machine top drawer saving space smoothly \n",
      "Original summary: nice \n",
      "Predicted summary:  wonderful\n",
      "\n",
      "\n",
      "Review: love tea dieting best always purchase tea family \n",
      "Original summary: wonderful \n",
      "Predicted summary:  tea\n",
      "\n",
      "\n",
      "Review: using mushrooms cooking twenty plus years roland extra fancy purchased best ever used including mushrooms bought italy back usa \n",
      "Original summary: an excellent product \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: deal awesome arrived halloween indicated enough satisfy trick love quality product much less expensive local store candy \n",
      "Original summary: awesome deal \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: product weak could even make supposed hot chocolate never buy waste money \n",
      "Original summary: okay hot chocolate \n",
      "Predicted summary:  not like the money\n",
      "\n",
      "\n",
      "Review: mix makes delicious pancakes gluten eating family wanted mine instead also make sausage balls biscuits biscuits gravy good \n",
      "Original summary: best pancakes \n",
      "Predicted summary:  best brownies ever\n",
      "\n",
      "\n",
      "Review: disappointed tried pancake mix going gluten free bisquick go pancake mix high expectations gluten free mix texture little weird soft dry prefer pamela pancake mix one \n",
      "Original summary: so so pancake mix \n",
      "Predicted summary:  not like the best\n",
      "\n",
      "\n",
      "Review: crackers amazing absolutely love anyone never buy another cracker quality outstanding italian crackers taste like mother used make lived italy \n",
      "Original summary: best crackers ever \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: switched decaf looking decent cup keurig machine interested subscribe save options fairly light roast like brew middle setting think brewed larger would think light \n",
      "Original summary: pretty good decaf \n",
      "Predicted summary:  best coffee\n",
      "\n",
      "\n",
      "Review: really choice comes soy dairy free baking uses palm kernel oil consistancy regular seems bake fine need soy dairy free highly recommend \n",
      "Original summary: the only soy and free \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: reading previous comments people stated know flavored coffee clearly states bought mine brought amazon secure delightful flavored coffee pleasant wake morning \n",
      "Original summary: outstanding \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: older dog medium size mixed breed back problems also tea cup pom surgery love treat ingredients good easy way get take glucosamine chondroitin need \n",
      "Original summary: my dogs love this product \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: cookies really good unlike many offering cookies well packed none broken good value found store \n",
      "Original summary: cookies \n",
      "Predicted summary:  cookies\n",
      "\n",
      "\n",
      "Review: one favorite teas digestion probably drink cups tea every day \n",
      "Original summary: stomach tea \n",
      "Predicted summary:  tea\n",
      "\n",
      "\n",
      "Review: received product timely manner quality product good product well purpose ordered thanks \n",
      "Original summary: tasty \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: delicious salty sit eat ounce bags time give stars plus stop eating delicious \n",
      "Original summary: potato chips \n",
      "Predicted summary:  not like\n",
      "\n",
      "\n",
      "Review: using spike seasoning six years think great use almost meats soups stews \n",
      "Original summary: seasoning is great \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: love oil use mainly cooking hair order amazon cannot find \n",
      "Original summary: great purchase \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: dog little maltese loves product knows get reward business works every time also received product timely fashion thanks amazon \n",
      "Original summary: dog loves it \n",
      "Predicted summary:  my dog loves these\n",
      "\n",
      "\n",
      "Review: good tasting tea need sugar drinking one cup per day usually mid day blood pressure sure long takes help lower helps even little worth drinking especially since tasty \n",
      "Original summary: tea \n",
      "Predicted summary:  tea\n",
      "\n",
      "\n",
      "Review: carbonated version orange celcius drink perfect drink first thing morning starts day right drinking half celcius morning couple years long get keep starting day celcius \n",
      "Original summary: best morning drink \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: found tea excellent reason stars instead shop get one containers open thing well sealed \n",
      "Original summary: yummy tea \n",
      "Predicted summary:  tea\n",
      "\n",
      "\n",
      "Review: ghee delicious little goes long way flavor wonderful aroma vegetable dishes burn easily like butter highly recommended \n",
      "Original summary: delicious \n",
      "Predicted summary:  best hot chocolate ever\n",
      "\n",
      "\n",
      "Review: poor product thinking looking mail order seafood amazon buy locally \n",
      "Original summary: sour and gross \n",
      "Predicted summary:  not\n",
      "\n",
      "\n",
      "Review: absolutely best hot chocolate sweet adults kids easy make add milk intense mixing required dissolves easily \n",
      "Original summary: the best hot cocoa \n",
      "Predicted summary:  best hot chocolate ever\n",
      "\n",
      "\n",
      "Review: always loved apple butter pb makes great glaze pork also touch apple salad plain apple always brand quality taste \n",
      "Original summary: butter not just for \n",
      "Predicted summary:  best brownies\n",
      "\n",
      "\n",
      "Review: really sure product would work expectations never buy ready made cups truly product \n",
      "Original summary: much better than \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: glutino crackers taste better gluten free crackers tried nice many choices available need alternatives \n",
      "Original summary: crackers \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: glad finally available boyfriend loves try buy every month \n",
      "Original summary: microwave pork rinds \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: good prefer taste baking mixes scratch store bought pretty good much cheaper local grocery stores per box local stores area \n",
      "Original summary: bisquick \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: truly enjoy good cup coffee give morning wolfgang puck really knows produce fine cup thanks \n",
      "Original summary: great cup of coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: lived us yrs miss twizzlers go back visit someone visits always stock say yum sell mexico buyer often able buy right \n",
      "Original summary: please these in \n",
      "Predicted summary:  my\n",
      "\n",
      "\n",
      "Review: kiwi berry flavor sweet taste neither strawberry kiwi overpowering instead best flavors little carbonation favorite switch flavor \n",
      "Original summary: but sweet \n",
      "Predicted summary:  best gf cracker\n",
      "\n",
      "\n",
      "Review: dog loves treat aware whenever go stored give treat long hair etc \n",
      "Original summary: perfect treat \n",
      "Predicted summary:  my dog loves these\n",
      "\n",
      "\n",
      "Review: love coffee ounces per always make two time best tasting never anything great coffee dolce gusto \n",
      "Original summary: coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: love chocolate found one best cookie real chocolate chunks every bit dream trust im real chocolate lover one black diamond read somebody said cheap product cookies super \n",
      "Original summary: yumm \n",
      "Predicted summary:  best brownies ever\n",
      "\n",
      "\n",
      "Review: thai coconut ginger noodles quick easy prepare delicious noodles enjoy share side dish another noodle \n",
      "Original summary: tasty and easy \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: tea excellent tea hot making iced tea great flavor aftertaste \n",
      "Original summary: tea \n",
      "Predicted summary:  tea\n",
      "\n",
      "\n",
      "Review: happy made purchase exactly think good value arrived quickly spike honestly best \n",
      "Original summary: good value \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: often bag sitting around work snacking really contrast snack foods \n",
      "Original summary: love this stuff \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: bought packet individual creamers keep track calories one creamer calories delicious add great flavor coffee recommended also store since last quite time enjoy cup coffee \n",
      "Original summary: delicious flavor \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: tried almost every meal one simply filling lunch dinner even snack tv know something good \n",
      "Original summary: out here \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: little one loves line food love convenient europe two weeks packed ton trip several easy convenient healthy love \n",
      "Original summary: perfect for \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: made peanut butter flour surprisingly good need put salt sweetner one taste personally like plain cannot beat lower calories lower fat price \n",
      "Original summary: great alternative to peanut butter \n",
      "Predicted summary:  best brownies ever\n",
      "\n",
      "\n",
      "Review: love french vanilla coffee gives day great start easy use one cup time waste \n",
      "Original summary: delicious \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: good deal flavor often carried stores honey berry flaver good thing things nature yum \n",
      "Original summary: drops \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: one eats cannot give best review son gobbles take star rating give stars since know organic worry eating review vegetables might star seem care peas much \n",
      "Original summary: great for on the go \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: affordable product works well quite like enough plants reason spend money expensive moisture cheap effective product starts \n",
      "Original summary: healthy no more over \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: interesting fun way spend evening tablet somewhat tart flavor sampled everything cheese fruits salt vinegar chips much great little mouth \n",
      "Original summary: fun little \n",
      "Predicted summary:  not\n",
      "\n",
      "\n",
      "Review: used two months sure helped dog still thinks already cut back cut back recommendation product directions loves taste lost even pounds would surprised worse though seem hunger \n",
      "Original summary: it or it \n",
      "Predicted summary:  pill pockets\n",
      "\n",
      "\n",
      "Review: enjoyable tea refreshing taste count pack excellent buy compared store prices \n",
      "Original summary: my tea \n",
      "Predicted summary:  tea\n",
      "\n",
      "\n",
      "Review: coffee awesome kinda bold sweetness excellent son says international creamer find dairy section \n",
      "Original summary: for coffee lovers \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: best coffee wake morning bitter right enjoyed served \n",
      "Original summary: best coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: love things unlike products actually tastes really good would recommend family friends \n",
      "Original summary: awesome \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: dog heart failure cannot standard dog treats salt perfect likes hunt snacks perfect toss let go nuts really likes \n",
      "Original summary: got them for my dog with \n",
      "Predicted summary:  dog treats\n",
      "\n",
      "\n",
      "Review: chip addict far tastiest non homemade chips ever plus healthy problem cannot decide flavor favorite \n",
      "Original summary: yum \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: love belgian waffles mix makes delicious waffle without trouble making scratch really good fussy tried pancakes yet \n",
      "Original summary: great taste and great price \n",
      "Predicted summary:  yummy\n",
      "\n",
      "\n",
      "Review: somewhat disappointed apple chips purchased apple chips past really loved thought would similar rather tasteless chips big mushy consistency would buy \n",
      "Original summary: chips \n",
      "Predicted summary:  not good\n",
      "\n",
      "\n",
      "Review: gf diet months used new product old quality company excellent results still use variety box goes long way little expensive worth \n",
      "Original summary: bisquick good \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: yumm sat cafe along eating vanilla ice cream syrup top fell love cherries strong taste cherry syrup taste sensation watch could get addicted \n",
      "Original summary: in can \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: never problem anything amazon ordered cases earth best baby food tasty nutritious variety offer grams protein iron subscribe save cannot get enough eats everyday \n",
      "Original summary: my son loves these \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: stuff really works middle pop water bottle set flavor fine goes easy \n",
      "Original summary: great for \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: service excellent product looking price fault wife wanted could find anywhere days got went sunflower food stores found identical item thank service better next time bill \n",
      "Original summary: great product but way to expensive \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: reese consistently excellent always makes popcorn taste great use brand buy bulk prefer plain salt version cheesy quite good \n",
      "Original summary: popcorn lover \n",
      "Predicted summary:  not like\n",
      "\n",
      "\n",
      "Review: try vanilla tootsie rolls regular chocolate ones good best ever \n",
      "Original summary: vanilla \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: always hated starbucks burnt bitter taste great blend still strong without burn roasting low quality beans burned hide bad taste \n",
      "Original summary: perfect blend \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTkaYNjHW4lC"
   },
   "source": [
    "\n",
    "### Future work\n",
    "\n",
    "TO develop using different types of deep learning models and compare the evaluation metrics\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "How to build own text summarizer using deep learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
